{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "from snowballstemmer import stemmer\n",
    "ar_stemmer = stemmer(\"arabic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"vaguely_ML_masters/data/raw/2018-Valence-oc-Ar-train.txt\"\n",
    "dev_path = \"vaguely_ML_masters/data/raw/2018-Valence-oc-Ar-dev.txt\"\n",
    "test_path = \"vaguely_ML_masters/data/raw/2018-Valence-oc-Ar-test.txt\"\n",
    "\n",
    "training_outpath = \"vaguely_ML_masters/data/cleaned/Ar_cleaned_training.txt\"\n",
    "dev_outpath = \"vaguely_ML_masters/data/cleaned/Ar_cleaned_dev.txt\"\n",
    "test_outpath = \"vaguely_ML_masters/data/cleaned/Ar_cleaned_test.txt\"\n",
    "\n",
    "stopwords_path = \"vaguely_ML_masters/utilities/arabic-stop-words-list.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-Ar-01961</td>\n",
       "      <td>إلىٰ متىٰ الألم يغلب على الفرح</td>\n",
       "      <td>valence</td>\n",
       "      <td>-3: very negative emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-Ar-03289</td>\n",
       "      <td>@Al3mriRami @Holyliviuss كل مافي الأمر أني غاضب أننا لا نظهر ولا نقدم أساطيرنا بأنفسنا\\nغاضب على أنفسنا وليس الغرب</td>\n",
       "      <td>valence</td>\n",
       "      <td>-2: moderately negative emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-Ar-04349</td>\n",
       "      <td>يحذركم ويخوفكم من نفسه اذا ارتكبتم ذنب او معصيه فانه سينزل بكم عقابه #كنوز #دار_الريان_النسائيه ~~</td>\n",
       "      <td>valence</td>\n",
       "      <td>-2: moderately negative emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-Ar-03640</td>\n",
       "      <td>💞 💞 صباحكم سعادة في اليوم المبارك تقبل الله صيامنا وقيامنا 💞 💞</td>\n",
       "      <td>valence</td>\n",
       "      <td>3: very positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-Ar-01176</td>\n",
       "      <td>@sjalmulla شفته قبل اسبوع ومتشوقه عليه وايد الصراحه 😍😍😍 بالتوفيق يارب ❤️</td>\n",
       "      <td>valence</td>\n",
       "      <td>2: moderately positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>927</td>\n",
       "      <td>2018-Ar-01836</td>\n",
       "      <td>@GafnZx 😳\\n\\nهذا بالحلال يابنت  الحلال👌🏻😀🎉</td>\n",
       "      <td>valence</td>\n",
       "      <td>1: slightly positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>928</td>\n",
       "      <td>2018-Ar-03475</td>\n",
       "      <td>الصادم في حقيقة الامر ان خلود رجعت مشاكسة مثل قبل وتضايقني مجددا وكأننا لم نتحدث بهدوء قبل قليل</td>\n",
       "      <td>valence</td>\n",
       "      <td>-2: moderately negative emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>929</td>\n",
       "      <td>2018-Ar-01490</td>\n",
       "      <td>كل تلك الأكتاف قادرة على حمل رأسك لكن و ل سوء حظك ليس بينهم الكتف التي تحب #وجع</td>\n",
       "      <td>valence</td>\n",
       "      <td>-1: slightly negative emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>2018-Ar-01710</td>\n",
       "      <td>بسم الله الرحمن الرحيم اعوذ بالله ماحسيت بطعم الرعب صدق الا لما سولفت معي وحده نايمه😭</td>\n",
       "      <td>valence</td>\n",
       "      <td>-2: moderately negative emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>2018-Ar-02662</td>\n",
       "      <td>بتخاف ع اخواتها اوى دايما سر اخوها بتكون فرحة البيت مبيعرفش قيمتها غير اللى مخلفش بنات وﻻ اﻻخ اللى ملوش اخت</td>\n",
       "      <td>valence</td>\n",
       "      <td>0: neutral or mixed emotional state can be inferred</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  \\\n",
       "0    2018-Ar-01961   \n",
       "1    2018-Ar-03289   \n",
       "2    2018-Ar-04349   \n",
       "3    2018-Ar-03640   \n",
       "4    2018-Ar-01176   \n",
       "..             ...   \n",
       "927  2018-Ar-01836   \n",
       "928  2018-Ar-03475   \n",
       "929  2018-Ar-01490   \n",
       "930  2018-Ar-01710   \n",
       "931  2018-Ar-02662   \n",
       "\n",
       "                                                                                                                  Tweet  \\\n",
       "0    إلىٰ متىٰ الألم يغلب على الفرح                                                                                       \n",
       "1    @Al3mriRami @Holyliviuss كل مافي الأمر أني غاضب أننا لا نظهر ولا نقدم أساطيرنا بأنفسنا\\nغاضب على أنفسنا وليس الغرب   \n",
       "2    يحذركم ويخوفكم من نفسه اذا ارتكبتم ذنب او معصيه فانه سينزل بكم عقابه #كنوز #دار_الريان_النسائيه ~~                   \n",
       "3    💞 💞 صباحكم سعادة في اليوم المبارك تقبل الله صيامنا وقيامنا 💞 💞                                                       \n",
       "4    @sjalmulla شفته قبل اسبوع ومتشوقه عليه وايد الصراحه 😍😍😍 بالتوفيق يارب ❤️                                             \n",
       "..                                                                        ...                                             \n",
       "927  @GafnZx 😳\\n\\nهذا بالحلال يابنت  الحلال👌🏻😀🎉                                                                           \n",
       "928  الصادم في حقيقة الامر ان خلود رجعت مشاكسة مثل قبل وتضايقني مجددا وكأننا لم نتحدث بهدوء قبل قليل                      \n",
       "929  كل تلك الأكتاف قادرة على حمل رأسك لكن و ل سوء حظك ليس بينهم الكتف التي تحب #وجع                                      \n",
       "930  بسم الله الرحمن الرحيم اعوذ بالله ماحسيت بطعم الرعب صدق الا لما سولفت معي وحده نايمه😭                                \n",
       "931  بتخاف ع اخواتها اوى دايما سر اخوها بتكون فرحة البيت مبيعرفش قيمتها غير اللى مخلفش بنات وﻻ اﻻخ اللى ملوش اخت          \n",
       "\n",
       "    Affect Dimension                                          Intensity Class  \n",
       "0    valence          -3: very negative emotional state can be inferred        \n",
       "1    valence          -2: moderately negative emotional state can be inferred  \n",
       "2    valence          -2: moderately negative emotional state can be inferred  \n",
       "3    valence          3: very positive emotional state can be inferred         \n",
       "4    valence          2: moderately positive emotional state can be inferred   \n",
       "..       ...                                                             ...   \n",
       "927  valence          1: slightly positive emotional state can be inferred     \n",
       "928  valence          -2: moderately negative emotional state can be inferred  \n",
       "929  valence          -1: slightly negative emotional state can be inferred    \n",
       "930  valence          -2: moderately negative emotional state can be inferred  \n",
       "931  valence          0: neutral or mixed emotional state can be inferred      \n",
       "\n",
       "[932 rows x 4 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_table(training_path)\n",
    "dev_df = pd.read_table(dev_path)\n",
    "test_df = pd.read_table(test_path)\n",
    "\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(stopwords_path, \"r\", encoding=\"utf-8\") as infile: \n",
    "    stopwords = list()\n",
    "    for line in infile:\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        stopwords.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_valence_scores(df): \n",
    "    valence_list = list()\n",
    "    for index, row in df.iterrows():\n",
    "        valence = row[\"Intensity Class\"]\n",
    "        valence = valence.replace(valence, valence[:2].replace(\":\", \"\"))\n",
    "        valence_list.append(valence)\n",
    "    return valence_list\n",
    "        \n",
    "training_valence = adapt_valence_scores(training_df)\n",
    "dev_valence = adapt_valence_scores(dev_df)\n",
    "test_valence = adapt_valence_scores(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    From https://towardsdatascience.com/sentiment-analysis-with-text-mining-13dd2b33de27\n",
    "    \"\"\"\n",
    "    def remove_repeating_char(self, input_text):\n",
    "        return re.sub(r'(.)\\1+', r'\\1\\1', input_text) #keep 2 repeat\n",
    "    \n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r\"http\\S+ | www\\S+\" , \"لينك\", input_text)\n",
    "    \n",
    "    def remove_hashtags(self, input_text):\n",
    "        return re.sub(r\"#\", \"\", input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)\n",
    "    \n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        ### whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords) and len(word) > 1] \n",
    "        return \" \".join(clean_words)\n",
    "    \n",
    "    def stem(self, input_text):\n",
    "        words = input_text.split()\n",
    "        stemmed_words = [ar_stemmer.stemWord(word) for word in words]\n",
    "        return \" \".join(stemmed_words)\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_hashtags).apply(self.remove_repeating_char).apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.remove_stopwords).apply(self.stem)\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CleanText()\n",
    "training_clean = ct.fit_transform(training_df.Tweet)\n",
    "dev_clean = ct.fit_transform(dev_df.Tweet)\n",
    "test_clean = ct.fit_transform(test_df.Tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      الىٰ متىٰ الم يغلب فرح                                                                  \n",
       "1      ماف امر ان غاضب اننا نظهر نقدم اساطير انفس nغاضب انفس غرب                               \n",
       "2      يحذر يخوف ارتكب ذنب معص ينزل بكم عقاب كنوز دارالريانالنساء                              \n",
       "3      صباح سعاد مبارك تقبل صيام قيام                                                          \n",
       "4      شفت اسبوع متشوق وايد صراحه 😍😍 توفيق يارب ❤️                                             \n",
       "                          ...                                                                  \n",
       "927    nهذ حلال يابن حلال👌🏻😀🎉                                                                  \n",
       "928    صادم حقيق امر خلود رجع مشاكس تضايق مجدد وكء نتحدث هدوء قليل                             \n",
       "929    اكتاف قادر حمل راس سوء حظك كتف تحب وجع                                                  \n",
       "930    بسم رحم رحيم اعوذ بالله ماحسي طعم رعب صدق سولف مع وحد نايمه😭                            \n",
       "931    تخاف اخوا اوي دايم سر اخو تكون فرح بيت مبيعرفش قيم اللي مخلفش بنا ولا الاخ اللي ملوش اخت\n",
       "Name: Tweet, Length: 932, dtype: object"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cleaned = pd.DataFrame(training_clean)\n",
    "training_cleaned['Valence score']= training_valence\n",
    "\n",
    "dev_cleaned = pd.DataFrame(dev_clean)\n",
    "dev_cleaned['Valence score']= dev_valence\n",
    "\n",
    "test_cleaned = pd.DataFrame(test_clean)\n",
    "test_cleaned['Valence score']= test_valence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cleaned.to_csv(training_outpath, sep=\"\\t\")\n",
    "dev_cleaned.to_csv(dev_outpath, sep=\"\\t\")\n",
    "test_cleaned.to_csv(test_outpath, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Valence score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>الىٰ متىٰ الم يغلب فرح</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ماف امر ان غاضب اننا نظهر نقدم اساطير انفس nغاضب انفس غرب</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>يحذر يخوف ارتكب ذنب معص ينزل بكم عقاب كنوز دارالريانالنساء</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>صباح سعاد مبارك تقبل صيام قيام</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>شفت اسبوع متشوق وايد صراحه 😍😍 توفيق يارب ❤️</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>927</td>\n",
       "      <td>nهذ حلال يابن حلال👌🏻😀🎉</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>928</td>\n",
       "      <td>صادم حقيق امر خلود رجع مشاكس تضايق مجدد وكء نتحدث هدوء قليل</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>929</td>\n",
       "      <td>اكتاف قادر حمل راس سوء حظك كتف تحب وجع</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>930</td>\n",
       "      <td>بسم رحم رحيم اعوذ بالله ماحسي طعم رعب صدق سولف مع وحد نايمه😭</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>931</td>\n",
       "      <td>تخاف اخوا اوي دايم سر اخو تكون فرح بيت مبيعرفش قيم اللي مخلفش بنا ولا الاخ اللي ملوش اخت</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>932 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                        Tweet  \\\n",
       "0    الىٰ متىٰ الم يغلب فرح                                                                     \n",
       "1    ماف امر ان غاضب اننا نظهر نقدم اساطير انفس nغاضب انفس غرب                                  \n",
       "2    يحذر يخوف ارتكب ذنب معص ينزل بكم عقاب كنوز دارالريانالنساء                                 \n",
       "3    صباح سعاد مبارك تقبل صيام قيام                                                             \n",
       "4    شفت اسبوع متشوق وايد صراحه 😍😍 توفيق يارب ❤️                                                \n",
       "..                                           ...                                                \n",
       "927  nهذ حلال يابن حلال👌🏻😀🎉                                                                     \n",
       "928  صادم حقيق امر خلود رجع مشاكس تضايق مجدد وكء نتحدث هدوء قليل                                \n",
       "929  اكتاف قادر حمل راس سوء حظك كتف تحب وجع                                                     \n",
       "930  بسم رحم رحيم اعوذ بالله ماحسي طعم رعب صدق سولف مع وحد نايمه😭                               \n",
       "931  تخاف اخوا اوي دايم سر اخو تكون فرح بيت مبيعرفش قيم اللي مخلفش بنا ولا الاخ اللي ملوش اخت   \n",
       "\n",
       "    Valence score  \n",
       "0    -3            \n",
       "1    -2            \n",
       "2    -2            \n",
       "3    3             \n",
       "4    2             \n",
       "..  ..             \n",
       "927  1             \n",
       "928  -2            \n",
       "929  -1            \n",
       "930  -2            \n",
       "931  0             \n",
       "\n",
       "[932 rows x 2 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
