{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "from time import time\n",
    "import re\n",
    "import string\n",
    "import os\n",
    "import emoji\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"2018-Valence-oc-En-train.txt\"\n",
    "dev_path = \"2018-Valence-oc-En-dev.txt\"\n",
    "test_path = \"2018-Valence-oc-En-test-gold.txt\"\n",
    "\n",
    "training_outpath = \"cleaned_training.txt\"\n",
    "dev_outpath = \"cleaned_dev.txt\"\n",
    "test_outpath = \"cleaned_test.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Affect Dimension</th>\n",
       "      <th>Intensity Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2018-En-01964</td>\n",
       "      <td>Gm and have a  #Tuesday!</td>\n",
       "      <td>valence</td>\n",
       "      <td>0: neutral or mixed emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2018-En-01539</td>\n",
       "      <td>@realDonaldTrump But you have a lot of time for tweeting #ironic</td>\n",
       "      <td>valence</td>\n",
       "      <td>0: neutral or mixed emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2018-En-04235</td>\n",
       "      <td>I graduated yesterday and already had 8 family members asking what job I've got now ðŸ˜‚ #nightmare</td>\n",
       "      <td>valence</td>\n",
       "      <td>0: neutral or mixed emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2018-En-03711</td>\n",
       "      <td>@jaimitoelcrack7 Seriously...I've been sitting here for five minutes watching this in awe. It never gets less amazing.</td>\n",
       "      <td>valence</td>\n",
       "      <td>1: slightly positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2018-En-01177</td>\n",
       "      <td>Whether my glass is half empty or its half full. I'm just grateful I even have a glass and that there's something in it.\\n #optimism ðŸ¤”</td>\n",
       "      <td>valence</td>\n",
       "      <td>2: moderately positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>932</td>\n",
       "      <td>2018-En-04059</td>\n",
       "      <td>Premier League Teams should fear next seasons Arsenal's XI. #coyg #afc</td>\n",
       "      <td>valence</td>\n",
       "      <td>0: neutral or mixed emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>933</td>\n",
       "      <td>2018-En-01488</td>\n",
       "      <td>how are you my love? @Hashtag_DonJon love youu!! thanks for the smile, that motivates me to keep going!! ðŸ’› so blessed to have you ðŸ˜Š</td>\n",
       "      <td>valence</td>\n",
       "      <td>3: very positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>934</td>\n",
       "      <td>2018-En-02648</td>\n",
       "      <td>'She is the clothed with strength and dignity, and she laughs without fear of the future.' ðŸ’›ðŸŒ¿ @jessconte</td>\n",
       "      <td>valence</td>\n",
       "      <td>0: neutral or mixed emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>935</td>\n",
       "      <td>2018-En-03444</td>\n",
       "      <td>My dads big day is only less than 2 weeks away. ðŸ˜± #excited</td>\n",
       "      <td>valence</td>\n",
       "      <td>3: very positive emotional state can be inferred</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>936</td>\n",
       "      <td>2018-En-04040</td>\n",
       "      <td>And let the depression take the stage once more ðŸ™ƒ</td>\n",
       "      <td>valence</td>\n",
       "      <td>-3: very negative emotional state can be inferred</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>937 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID  \\\n",
       "0    2018-En-01964   \n",
       "1    2018-En-01539   \n",
       "2    2018-En-04235   \n",
       "3    2018-En-03711   \n",
       "4    2018-En-01177   \n",
       "..             ...   \n",
       "932  2018-En-04059   \n",
       "933  2018-En-01488   \n",
       "934  2018-En-02648   \n",
       "935  2018-En-03444   \n",
       "936  2018-En-04040   \n",
       "\n",
       "                                                                                                                                      Tweet  \\\n",
       "0    Gm and have a  #Tuesday!                                                                                                                 \n",
       "1    @realDonaldTrump But you have a lot of time for tweeting #ironic                                                                         \n",
       "2    I graduated yesterday and already had 8 family members asking what job I've got now ðŸ˜‚ #nightmare                                         \n",
       "3    @jaimitoelcrack7 Seriously...I've been sitting here for five minutes watching this in awe. It never gets less amazing.                   \n",
       "4    Whether my glass is half empty or its half full. I'm just grateful I even have a glass and that there's something in it.\\n #optimism ðŸ¤”   \n",
       "..                                                                                                                                      ...   \n",
       "932  Premier League Teams should fear next seasons Arsenal's XI. #coyg #afc                                                                   \n",
       "933  how are you my love? @Hashtag_DonJon love youu!! thanks for the smile, that motivates me to keep going!! ðŸ’› so blessed to have you ðŸ˜Š      \n",
       "934  'She is the clothed with strength and dignity, and she laughs without fear of the future.' ðŸ’›ðŸŒ¿ @jessconte                                 \n",
       "935  My dads big day is only less than 2 weeks away. ðŸ˜± #excited                                                                               \n",
       "936  And let the depression take the stage once more ðŸ™ƒ                                                                                        \n",
       "\n",
       "    Affect Dimension                                         Intensity Class  \n",
       "0    valence          0: neutral or mixed emotional state can be inferred     \n",
       "1    valence          0: neutral or mixed emotional state can be inferred     \n",
       "2    valence          0: neutral or mixed emotional state can be inferred     \n",
       "3    valence          1: slightly positive emotional state can be inferred    \n",
       "4    valence          2: moderately positive emotional state can be inferred  \n",
       "..       ...                                                             ...  \n",
       "932  valence          0: neutral or mixed emotional state can be inferred     \n",
       "933  valence          3: very positive emotional state can be inferred        \n",
       "934  valence          0: neutral or mixed emotional state can be inferred     \n",
       "935  valence          3: very positive emotional state can be inferred        \n",
       "936  valence          -3: very negative emotional state can be inferred       \n",
       "\n",
       "[937 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df = pd.read_table(training_path)\n",
    "dev_df = pd.read_table(dev_path)\n",
    "test_df = pd.read_table(test_path)\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adapt_valence_scores(df): \n",
    "    valence_list = list()\n",
    "    for index, row in df.iterrows():\n",
    "        valence = row[\"Intensity Class\"]\n",
    "        valence = valence.replace(valence, valence[:2].replace(\":\", \"\"))\n",
    "        valence_list.append(valence)\n",
    "    return valence_list\n",
    "        \n",
    "training_valence = adapt_valence_scores(training_df)\n",
    "dev_valence = adapt_valence_scores(dev_df)\n",
    "test_valence = adapt_valence_scores(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CleanText(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    From https://towardsdatascience.com/sentiment-analysis-with-text-mining-13dd2b33de27\n",
    "    \"\"\"\n",
    "    def remove_mentions(self, input_text):\n",
    "        return re.sub(r'@\\w+', '', input_text)\n",
    "    \n",
    "    def remove_urls(self, input_text):\n",
    "        return re.sub(r'http.?://[^\\s]+[\\s]?', '', input_text)\n",
    "    \n",
    "    def emoji_oneword(self, input_text):\n",
    "        # By compressing the underscore, the emoji is kept as one word\n",
    "        return input_text.replace('_','')\n",
    "    \n",
    "    def remove_punctuation(self, input_text):\n",
    "        # Make translation table\n",
    "        punct = string.punctuation\n",
    "        trantab = str.maketrans(punct, len(punct)*' ')  # Every punctuation symbol will be replaced by a space\n",
    "        return input_text.translate(trantab)\n",
    "    \n",
    "    def remove_digits(self, input_text):\n",
    "        return re.sub('\\d+', '', input_text)\n",
    "    \n",
    "    def to_lower(self, input_text):\n",
    "        return input_text.lower()\n",
    "    \n",
    "    def remove_stopwords(self, input_text):\n",
    "        stopwords_list = stopwords.words('english')\n",
    "        # Some words which might indicate a certain sentiment are kept via a whitelist\n",
    "        whitelist = [\"n't\", \"not\", \"no\"]\n",
    "        words = input_text.split() \n",
    "        clean_words = [word for word in words if (word not in stopwords_list or word in whitelist) and len(word) > 1] \n",
    "        return \" \".join(clean_words) \n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, **transform_params):\n",
    "        clean_X = X.apply(self.remove_mentions).apply(self.remove_urls).apply(self.emoji_oneword).apply(self.remove_punctuation).apply(self.remove_digits).apply(self.to_lower).apply(self.remove_stopwords)\n",
    "        return clean_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = CleanText()\n",
    "training_clean = ct.fit_transform(training_df.Tweet)\n",
    "dev_clean = ct.fit_transform(dev_df.Tweet)\n",
    "test_clean = ct.fit_transform(test_df.Tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cleaned = pd.DataFrame(training_clean)\n",
    "training_cleaned['Valence score']= training_valence\n",
    "\n",
    "dev_cleaned = pd.DataFrame(dev_clean)\n",
    "dev_cleaned['Valence score']= dev_valence\n",
    "\n",
    "test_cleaned = pd.DataFrame(test_clean)\n",
    "test_cleaned['Valence score']= test_valence\n",
    "test_cleaned = test_cleaned.drop([271]) #Drop empty line from test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_cleaned.to_csv(training_outpath, sep=\"\\t\")\n",
    "dev_cleaned.to_csv(dev_outpath, sep=\"\\t\")\n",
    "test_cleaned.to_csv(test_outpath, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
